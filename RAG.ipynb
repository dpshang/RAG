{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving RAG by Averaging\n",
    "\n",
    "#### Authors: Gilyoung Cheong, Qidu Fu, Junichi Koganemaru, Xinyuan Lai, Sixuan Lou, Dapeng Shang\n",
    " \n",
    "This notebook is written as a part of the capstone project for the [Erd≈ës Institute Data Science Boot Camp](https://www.erdosinstitute.org/). The data used in this notebook is provided by Jason Morgan at AwareHQ. We use Gemma 2B-IT using HuggingFace API, which we learned from [this article](https://huggingface.co/learn/cookbook/en/rag_with_hugging_face_gemma_mongodb) by Richmond Alake.\n",
    "\n",
    "In this notebook, we implement some pipelines of [Retrieval-Augmented Generation (RAG)](https://aws.amazon.com/what-is/retrieval-augmented-generation/) using [SBERT](https://arxiv.org/abs/1908.10084) developed by Nils Reimers and Iryna Gurevych. The documentation for the SBERT API for Python is available in [this link](https://sbert.net/). We use SBERT to find relevant comments to a query from various reddit comments from previously saved data.\n",
    "\n",
    "The pretrained SBERT converts any sentence into a vector in $\\mathbb{R}^{1024}$, and the relevance of the two sentences is simply measured by the cosine similarity of the corresponding vectors. That is, if $\\boldsymbol{u}$ and $\\boldsymbol{v}$ are the vectors, we measure \n",
    "\n",
    "$$\\frac{\\langle \\boldsymbol{u}, \\boldsymbol{v} \\rangle}{\\|\\boldsymbol{u}\\|\\|\\boldsymbol{v}\\|},$$\n",
    "\n",
    "which can be intuitively thought as $\\cos(\\theta)$, where $\\theta$ is the angle between $\\boldsymbol{u}$ and $\\boldsymbol{v}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of SBERT vs BERT\n",
    "\n",
    "SBERT (Sentence Bert) is based on [BERT (Bidirectional Encoder Representations from Transformer)](https://arxiv.org/abs/1810.04805) developed by Google. From inspection, there are clear benefits of using SBERT over BERT for our purpose.\n",
    "\n",
    "1. BERT is designed to generate vectors that correspond to individual words (or more precisely, *subwords*) to a sentence, so each sentence is converted into not just a vector but a sequence of vectors. Hence, in order to examine the similaritiy of two sentences, we need to either pick one word or take the average of the vectors, which did not yield satisfying results.\n",
    "\n",
    "2. Because BERT converts every subword as a vector, in order to fully use it, we need to use a lot more storage. In an experiement, examining 10400 comments required 11.8GB with BERT while it only required 91.6MB with SBERT.\n",
    "\n",
    "3. For BERT, the query and the comments (i.e., information to answer the query) need to be proceeded together when we embedd them as (sequences of) vectors. For SBERT, we can vectorize the comments first and then indepedently vectorize the query later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "import os.path\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer # SBERT\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # HuggingFace API to use Gemma (LLM)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model for synthetic query generation\n",
    "tokenizer = T5Tokenizer.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')\n",
    "model = T5ForConditionalGeneration.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in reddit data and specifying columns to use\n",
    "columns = ['reddit_text', 'reddit_subreddit']\n",
    "df = pd.read_parquet(\"reddit.parquet\", engine='fastparquet', columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reddit_subreddit\n",
       "nursing                789499\n",
       "walmart                630962\n",
       "sysadmin               557558\n",
       "starbucks              393597\n",
       "WaltDisneyWorld        373138\n",
       "Target                 340401\n",
       "UPSers                 262483\n",
       "Disneyland             231981\n",
       "Lowes                  198805\n",
       "CVS                    179598\n",
       "McDonaldsEmployees     174679\n",
       "cybersecurity          161868\n",
       "Fedexers               154572\n",
       "GameStop               137071\n",
       "starbucksbaristas      132019\n",
       "fidelityinvestments    129423\n",
       "Bestbuy                121077\n",
       "wholefoods              82052\n",
       "Panera                  79436\n",
       "DisneyWorld             65549\n",
       "DollarTree              59745\n",
       "TjMaxx                  46286\n",
       "disney                  43954\n",
       "McLounge                38627\n",
       "GeneralMotors           37277\n",
       "TalesFromYourBank       28444\n",
       "cabincrewcareers        23408\n",
       "Chase                   16931\n",
       "KrakenSupport           14533\n",
       "WalmartEmployees        10752\n",
       "BestBuyWorkers           5629\n",
       "RiteAid                  3970\n",
       "PaneraEmployees          2694\n",
       "FedEmployees              280\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying candidate subreddits to analyze \n",
    "value_count = df['reddit_subreddit'].value_counts()\n",
    "value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reddit_subreddit\n",
       "wholefoods           82052\n",
       "Panera               79436\n",
       "DisneyWorld          65549\n",
       "DollarTree           59745\n",
       "TjMaxx               46286\n",
       "disney               43954\n",
       "McLounge             38627\n",
       "GeneralMotors        37277\n",
       "TalesFromYourBank    28444\n",
       "cabincrewcareers     23408\n",
       "Chase                16931\n",
       "KrakenSupport        14533\n",
       "WalmartEmployees     10752\n",
       "BestBuyWorkers        5629\n",
       "RiteAid               3970\n",
       "PaneraEmployees       2694\n",
       "FedEmployees           280\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For proof of concept, we decided to work with medium sized subreddits first\n",
    "value_count[ value_count < 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_subreddts = ['TalesFromYourBank', 'cabincrewcareers', 'Chase', 'KrakenSupport', 'WalmartEmployees', 'BestBuyWorkers', 'RiteAid', 'PaneraEmployees', 'FedEmployees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106641"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['reddit_subreddit'].isin(selected_subreddts)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic data cleaning by removing rows with empty/removed/deleted texts\n",
    "def remove_empty(df):\n",
    "    df = df[~(df['reddit_text'] == '')] # erasing empty reddit texts\n",
    "    df = df[~(df['reddit_text']=='[removed]')] # erasing removed reddit texts\n",
    "    df = df[~(df['reddit_text']=='[deleted]')] # erasing deleted reddit texts\n",
    "    df = df[df['reddit_text'].str.len() > 5] #Only kee ping responses longer than 5 characters\n",
    "    df = df.sort_values(by='reddit_text') # sort them by reddit texts\n",
    "    df = df.reset_index().drop(columns='index') # resetting indices\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www.\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "# Load stopwords\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:44: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:46: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:62: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:63: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:65: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:68: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:69: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:70: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:71: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:87: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:89: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:91: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:96: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:104: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:105: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:108: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:109: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:111: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:112: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:113: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:114: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:115: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:116: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:118: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:119: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:120: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:122: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:123: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:124: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:127: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:128: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:130: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:131: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:132: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:133: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:134: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:135: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:136: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:137: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:138: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:139: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:141: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:142: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:143: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:144: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:145: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:146: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:147: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:148: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:149: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:150: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:151: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:152: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:153: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:154: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:155: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:156: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:157: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:162: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:163: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:166: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:167: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:168: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:169: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:170: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:171: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:172: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:173: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:174: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:175: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:176: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:177: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:178: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:179: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:180: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:181: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:182: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:183: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:184: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:185: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:186: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:187: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:188: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:189: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:190: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:191: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:192: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:193: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:194: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:195: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:196: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:197: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:198: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:199: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:200: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:201: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:202: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:203: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:204: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:205: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:206: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:207: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:208: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:209: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:210: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:211: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:212: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:213: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:214: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:217: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:218: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:220: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:221: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:44: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:46: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:62: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:63: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:65: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:68: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:69: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:70: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:71: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:87: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:89: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:91: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:96: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:104: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:105: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:108: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:109: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:111: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:112: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:113: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:114: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:115: SyntaxWarning: invalid escape sequence '\\}'\n",
      "<>:116: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:118: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:119: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:120: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:122: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:123: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:124: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:127: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:128: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:130: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:131: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:132: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:133: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:134: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:135: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:136: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:137: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:138: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:139: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:140: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:141: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:142: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:143: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:144: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:145: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:146: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:147: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:148: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:149: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:150: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:151: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:152: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:153: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:154: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:155: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:156: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:157: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:162: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:163: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:166: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:167: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:168: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:169: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:170: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:171: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:172: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:173: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:174: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:175: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:176: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:177: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:178: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:179: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:180: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:181: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:182: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:183: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:184: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:185: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:186: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:187: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:188: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:189: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:190: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:191: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:192: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:193: SyntaxWarning: invalid escape sequence '\\^'\n",
      "<>:194: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:195: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:196: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:197: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:198: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:199: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:200: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:201: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:202: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:203: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:204: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:205: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:206: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:207: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:208: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:209: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:210: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:211: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:212: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:213: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:214: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:217: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:218: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:220: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:221: SyntaxWarning: invalid escape sequence '\\('\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":‚Äë\\)\":\"Happy face or smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:4: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":\\)\":\"Happy face or smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  u\":-\\]\":\"Happy face or smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  u\":\\]\":\"Happy face or smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:11: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"8-\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:12: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":o\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:13: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  u\":-\\}\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:14: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  u\":\\}\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:15: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":-\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:16: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":c\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:17: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\":\\^\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:18: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  u\"=\\]\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:19: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"=\\)\":\"Happy face smiley\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:28: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:29: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":-\\)\\)\":\"Very happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:30: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\":‚Äë\\(\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:31: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:32: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\":\\(\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:37: SyntaxWarning: invalid escape sequence '\\['\n",
      "  u\":‚Äë\\[\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:38: SyntaxWarning: invalid escape sequence '\\['\n",
      "  u\":\\[\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:39: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:40: SyntaxWarning: invalid escape sequence '\\['\n",
      "  u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:41: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  u\":\\{\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:43: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:44: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\":'‚Äë\\(\":\"Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:45: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\":'\\(\":\"Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:46: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":'‚Äë\\)\":\"Tears of happiness\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:47: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":'\\)\":\"Tears of happiness\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:62: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  u\":-\\*\":\"Kiss\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:63: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  u\":\\*\":\"Kiss\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:65: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\";‚Äë\\)\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:66: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\";\\)\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:67: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  u\"\\*-\\)\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:68: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  u\"\\*\\)\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:69: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  u\";‚Äë\\]\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:70: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  u\";\\]\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:71: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\";\\^\\)\":\"Wink or smirk\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:87: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:89: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:91: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:95: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\":‚Äë\\|\":\"Straight face\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:96: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\":\\|\":\"Straight face\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:104: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"O:‚Äë\\)\":\"Angel, saint or innocent\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:105: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"O:\\)\":\"Angel, saint or innocent\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:108: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"0:‚Äë\\)\":\"Angel, saint or innocent\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:109: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"0:\\)\":\"Angel, saint or innocent\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:111: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:112: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\">:‚Äë\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:113: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\">:\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:114: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  u\"\\}:‚Äë\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:115: SyntaxWarning: invalid escape sequence '\\}'\n",
      "  u\"\\}:\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:116: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"3:‚Äë\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:117: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"3:\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:118: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\">;\\)\":\"Evil or devilish\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:119: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\"\\|;‚Äë\\)\":\"Cool\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:120: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\"\\|‚ÄëO\":\"Bored\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:122: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"#‚Äë\\)\":\"Party all night\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:123: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"%‚Äë\\)\":\"Drunk or confused\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:124: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"%\\)\":\"Drunk or confused\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:127: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  u\"<:‚Äë\\|\":\"Dump\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:128: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(>_<\\)\":\"Troubled\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:129: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(>_<\\)>\":\"Troubled\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:130: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(';'\\)\":\"Baby\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:131: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:132: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:133: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:134: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(~_~;\\) \\(„Éª\\.„Éª;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:135: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:136: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_-\\)\":\"Wink\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:137: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:138: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\+o\\+\\)\":\"Confused\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:139: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(o\\|o\\)\":\"Ultraman\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:140: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"\\^_\\^\":\"Joyful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:141: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:142: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^O\\^\\)Ôºè\":\"Joyful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:143: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^o\\^\\)Ôºè\":\"Joyful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:144: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:145: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:146: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:147: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:148: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:149: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:150: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\('_'\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:151: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(/_;\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:152: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:153: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(;_;\":\"Sad of Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:154: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(;_:\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:155: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(;O;\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:156: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(:_;\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:157: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(ToT\\)\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:162: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  u\"Q\\.Q\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:163: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  u\"T\\.T\":\"Sad or Crying\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:166: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(-\\.-\\)\":\"Shame\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:167: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(-_-\\)\":\"Shame\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:168: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(‰∏Ä‰∏Ä\\)\":\"Shame\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:169: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(Ôºõ‰∏Ä_‰∏Ä\\)\":\"Shame\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:170: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(=_=\\)\":\"Tired\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:171: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(=\\^\\¬∑\\^=\\)\":\"cat\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:172: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(=\\^\\¬∑\\¬∑\\^=\\)\":\"cat\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:173: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"=_\\^=\t\":\"cat\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:174: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\.\\.\\)\":\"Looking down\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:175: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\._\\.\\)\":\"Looking down\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:176: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:177: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\„Éª\\„Éª?\":\"Confusion\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:178: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(?_?\\)\":\"Confusion\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:179: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\">\\^_\\^<\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:180: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"<\\^!\\^>\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:181: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"\\^/\\^\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:182: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  u\"\\Ôºà\\*\\^_\\^\\*Ôºâ\" :\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:183: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:184: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:185: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:186: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:187: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:188: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:189: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:190: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:191: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^‚Äî\\^\\Ôºâ\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:192: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:193: SyntaxWarning: invalid escape sequence '\\^'\n",
      "  u\"\\Ôºà\\^‚Äî\\^\\Ôºâ\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:194: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(;_;\\)/~~~\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:195: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:196: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(-_-\\)/~~~ \\($\\¬∑\\¬∑\\)/~~~\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:197: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(T_T\\)/~~~\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:198: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(ToT\\)/~~~\":\"Waving\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:199: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:200: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:201: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*_\\*;\":\"Amazed\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:202: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:203: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:204: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:205: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:206: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u'\\(-\"-\\)':\"Worried\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:207: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(„Éº„Éº;\\)\":\"Worried\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:208: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:209: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\ÔºæÔΩñ\\Ôºæ\\)\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:210: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\ÔºæÔΩï\\Ôºæ\\)\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:211: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:212: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^O\\^\\)\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:213: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\^o\\^\\)\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:214: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  u\"\\)\\^o\\^\\(\":\"Happy\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:217: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  u\"o\\.O\":\"Surpised\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:218: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(o\\.o\\)\":\"Surprised\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:220: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(\\*Ôø£mÔø£\\)\":\"Dissatisfied\",\n",
      "C:\\Users\\Gil\\AppData\\Local\\Temp\\ipykernel_7040\\1363537030.py:221: SyntaxWarning: invalid escape sequence '\\('\n",
      "  u\"\\(‚ÄòA`\\)\":\"Snubbed or Deflated\"\n"
     ]
    }
   ],
   "source": [
    "# from: https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "EMOTICONS = {\n",
    "    u\":‚Äë\\)\":\"Happy face or smiley\",\n",
    "    u\":\\)\":\"Happy face or smiley\",\n",
    "    u\":-\\]\":\"Happy face or smiley\",\n",
    "    u\":\\]\":\"Happy face or smiley\",\n",
    "    u\":-3\":\"Happy face smiley\",\n",
    "    u\":3\":\"Happy face smiley\",\n",
    "    u\":->\":\"Happy face smiley\",\n",
    "    u\":>\":\"Happy face smiley\",\n",
    "    u\"8-\\)\":\"Happy face smiley\",\n",
    "    u\":o\\)\":\"Happy face smiley\",\n",
    "    u\":-\\}\":\"Happy face smiley\",\n",
    "    u\":\\}\":\"Happy face smiley\",\n",
    "    u\":-\\)\":\"Happy face smiley\",\n",
    "    u\":c\\)\":\"Happy face smiley\",\n",
    "    u\":\\^\\)\":\"Happy face smiley\",\n",
    "    u\"=\\]\":\"Happy face smiley\",\n",
    "    u\"=\\)\":\"Happy face smiley\",\n",
    "    u\":‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"X‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":-\\)\\)\":\"Very happy\",\n",
    "    u\":‚Äë\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äëc\":\"Frown, sad, andry or pouting\",\n",
    "    u\":c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äë<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äë\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\{\":\"Frown, sad, andry or pouting\",\n",
    "    u\":@\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":'‚Äë\\(\":\"Crying\",\n",
    "    u\":'\\(\":\"Crying\",\n",
    "    u\":'‚Äë\\)\":\"Tears of happiness\",\n",
    "    u\":'\\)\":\"Tears of happiness\",\n",
    "    u\"D‚Äë':\":\"Horror\",\n",
    "    u\"D:<\":\"Disgust\",\n",
    "    u\"D:\":\"Sadness\",\n",
    "    u\"D8\":\"Great dismay\",\n",
    "    u\"D;\":\"Great dismay\",\n",
    "    u\"D=\":\"Great dismay\",\n",
    "    u\"DX\":\"Great dismay\",\n",
    "    u\":‚ÄëO\":\"Surprise\",\n",
    "    u\":O\":\"Surprise\",\n",
    "    u\":‚Äëo\":\"Surprise\",\n",
    "    u\":o\":\"Surprise\",\n",
    "    u\":-0\":\"Shock\",\n",
    "    u\"8‚Äë0\":\"Yawn\",\n",
    "    u\">:O\":\"Yawn\",\n",
    "    u\":-\\*\":\"Kiss\",\n",
    "    u\":\\*\":\"Kiss\",\n",
    "    u\":X\":\"Kiss\",\n",
    "    u\";‚Äë\\)\":\"Wink or smirk\",\n",
    "    u\";\\)\":\"Wink or smirk\",\n",
    "    u\"\\*-\\)\":\"Wink or smirk\",\n",
    "    u\"\\*\\)\":\"Wink or smirk\",\n",
    "    u\";‚Äë\\]\":\"Wink or smirk\",\n",
    "    u\";\\]\":\"Wink or smirk\",\n",
    "    u\";\\^\\)\":\"Wink or smirk\",\n",
    "    u\":‚Äë,\":\"Wink or smirk\",\n",
    "    u\";D\":\"Wink or smirk\",\n",
    "    u\":‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"X‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‚Äë√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‚Äë/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":‚Äë\\|\":\"Straight face\",\n",
    "    u\":\\|\":\"Straight face\",\n",
    "    u\":$\":\"Embarrassed or blushing\",\n",
    "    u\":‚Äëx\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‚Äë#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‚Äë&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\"O:‚Äë\\)\":\"Angel, saint or innocent\",\n",
    "    u\"O:\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:‚Äë3\":\"Angel, saint or innocent\",\n",
    "    u\"0:3\":\"Angel, saint or innocent\",\n",
    "    u\"0:‚Äë\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:\\)\":\"Angel, saint or innocent\",\n",
    "    u\":‚Äëb\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
    "    u\">:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\">:\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:\\)\":\"Evil or devilish\",\n",
    "    u\"3:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\"3:\\)\":\"Evil or devilish\",\n",
    "    u\">;\\)\":\"Evil or devilish\",\n",
    "    u\"\\|;‚Äë\\)\":\"Cool\",\n",
    "    u\"\\|‚ÄëO\":\"Bored\",\n",
    "    u\":‚ÄëJ\":\"Tongue-in-cheek\",\n",
    "    u\"#‚Äë\\)\":\"Party all night\",\n",
    "    u\"%‚Äë\\)\":\"Drunk or confused\",\n",
    "    u\"%\\)\":\"Drunk or confused\",\n",
    "    u\":-###..\":\"Being sick\",\n",
    "    u\":###..\":\"Being sick\",\n",
    "    u\"<:‚Äë\\|\":\"Dump\",\n",
    "    u\"\\(>_<\\)\":\"Troubled\",\n",
    "    u\"\\(>_<\\)>\":\"Troubled\",\n",
    "    u\"\\(';'\\)\":\"Baby\",\n",
    "    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(~_~;\\) \\(„Éª\\.„Éª;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
    "    u\"\\(\\^_-\\)\":\"Wink\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
    "    u\"\\(\\+o\\+\\)\":\"Confused\",\n",
    "    u\"\\(o\\|o\\)\":\"Ultraman\",\n",
    "    u\"\\^_\\^\":\"Joyful\",\n",
    "    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
    "    u\"\\(\\^O\\^\\)Ôºè\":\"Joyful\",\n",
    "    u\"\\(\\^o\\^\\)Ôºè\":\"Joyful\",\n",
    "    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"\\('_'\\)\":\"Sad or Crying\",\n",
    "    u\"\\(/_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;_;\":\"Sad of Crying\",\n",
    "    u\"\\(;_:\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;O;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(:_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(ToT\\)\":\"Sad or Crying\",\n",
    "    u\";_;\":\"Sad or Crying\",\n",
    "    u\";-;\":\"Sad or Crying\",\n",
    "    u\";n;\":\"Sad or Crying\",\n",
    "    u\";;\":\"Sad or Crying\",\n",
    "    u\"Q\\.Q\":\"Sad or Crying\",\n",
    "    u\"T\\.T\":\"Sad or Crying\",\n",
    "    u\"QQ\":\"Sad or Crying\",\n",
    "    u\"Q_Q\":\"Sad or Crying\",\n",
    "    u\"\\(-\\.-\\)\":\"Shame\",\n",
    "    u\"\\(-_-\\)\":\"Shame\",\n",
    "    u\"\\(‰∏Ä‰∏Ä\\)\":\"Shame\",\n",
    "    u\"\\(Ôºõ‰∏Ä_‰∏Ä\\)\":\"Shame\",\n",
    "    u\"\\(=_=\\)\":\"Tired\",\n",
    "    u\"\\(=\\^\\¬∑\\^=\\)\":\"cat\",\n",
    "    u\"\\(=\\^\\¬∑\\¬∑\\^=\\)\":\"cat\",\n",
    "    u\"=_\\^=\t\":\"cat\",\n",
    "    u\"\\(\\.\\.\\)\":\"Looking down\",\n",
    "    u\"\\(\\._\\.\\)\":\"Looking down\",\n",
    "    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
    "    u\"\\(\\„Éª\\„Éª?\":\"Confusion\",\n",
    "    u\"\\(?_?\\)\":\"Confusion\",\n",
    "    u\">\\^_\\^<\":\"Normal Laugh\",\n",
    "    u\"<\\^!\\^>\":\"Normal Laugh\",\n",
    "    u\"\\^/\\^\":\"Normal Laugh\",\n",
    "    u\"\\Ôºà\\*\\^_\\^\\*Ôºâ\" :\"Normal Laugh\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^‚Äî\\^\\Ôºâ\":\"Normal Laugh\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
    "    u\"\\Ôºà\\^‚Äî\\^\\Ôºâ\":\"Waving\",\n",
    "    u\"\\(;_;\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
    "    u\"\\(-_-\\)/~~~ \\($\\¬∑\\¬∑\\)/~~~\":\"Waving\",\n",
    "    u\"\\(T_T\\)/~~~\":\"Waving\",\n",
    "    u\"\\(ToT\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
    "    u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
    "    u\"\\(\\*_\\*;\":\"Amazed\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
    "    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
    "    u'\\(-\"-\\)':\"Worried\",\n",
    "    u\"\\(„Éº„Éº;\\)\":\"Worried\",\n",
    "    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
    "    u\"\\(\\ÔºæÔΩñ\\Ôºæ\\)\":\"Happy\",\n",
    "    u\"\\(\\ÔºæÔΩï\\Ôºæ\\)\":\"Happy\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^O\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^o\\^\\)\":\"Happy\",\n",
    "    u\"\\)\\^o\\^\\(\":\"Happy\",\n",
    "    u\":O o_O\":\"Surprised\",\n",
    "    u\"o_0\":\"Surprised\",\n",
    "    u\"o\\.O\":\"Surpised\",\n",
    "    u\"\\(o\\.o\\)\":\"Surprised\",\n",
    "    u\"oO\":\"Surprised\",\n",
    "    u\"\\(\\*Ôø£mÔø£\\)\":\"Dissatisfied\",\n",
    "    u\"\\(‚ÄòA`\\)\":\"Snubbed or Deflated\"\n",
    "}\n",
    "\n",
    "chat_words_str = \"\"\"\n",
    "afaik=As far as i know\n",
    "afk=away from keyboard\n",
    "asap=as soon as possible\n",
    "atk=at the keyboard\n",
    "atm=at the moment\n",
    "a3=anytime, anywhere, anyplace\n",
    "bak=back at keyboard\n",
    "bbl=be back later\n",
    "bbs=be back soon\n",
    "bfn=bye for now\n",
    "b4n=bye for now\n",
    "brb=be right back\n",
    "brt=be right there\n",
    "btw=by the way\n",
    "b4=before\n",
    "b4n=bye for now\n",
    "cu=see you\n",
    "cul8r=see you later\n",
    "cya=see you\n",
    "faq=frequently asked questions\n",
    "fc=fingers crossed\n",
    "fwiw=for what it's worth\n",
    "fyi=for your information\n",
    "gal=get a life\n",
    "gg=good game\n",
    "gn=good night\n",
    "gmta=great minds think alike\n",
    "gr8=great!\n",
    "g9=genius\n",
    "ic=I see\n",
    "icq=I seek you (also a chat program)\n",
    "ilu=ilu: I love you\n",
    "imho=in my honest/humble opinion\n",
    "imo=in my opinion\n",
    "iow=in other words\n",
    "irl=in real life\n",
    "kiss=keep it simple, stupid\n",
    "ldr=long distance relationship\n",
    "lmao=laugh my a.. off\n",
    "lol=laughing out loud\n",
    "ltns=long time no see\n",
    "l8r=later\n",
    "mte=my thoughts exactly\n",
    "m8=mate\n",
    "nrn=no reply necessary\n",
    "oic=oh I see\n",
    "pita=pain in the a..\n",
    "prt=party\n",
    "prw=parents are watching\n",
    "rofl=rolling on the floor laughing\n",
    "roflol=rolling on the floor laughing out loud\n",
    "rotflmao=rolling on the floor laughing my a.. off\n",
    "sk8=skate\n",
    "stats=your sex and age\n",
    "asl=age, sex, location\n",
    "thx=thank you\n",
    "ttfn=ta-ta for now!\n",
    "ttyl=talk to you later\n",
    "u=you\n",
    "u2=you too\n",
    "u4e=yours for ever\n",
    "wb=welcome back\n",
    "wtf=what the f...\n",
    "wtg=way to go!\n",
    "wuf=where are you from?\n",
    "w8=wait...\n",
    "7k=sick:-d laugher\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove emoticons\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "#Remove emojis\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat word conversion\n",
    "def build_chat_word_mapping(chat_words_str):\n",
    "    mapping = {}\n",
    "    cw_set = set()\n",
    "    for line in chat_words_str.split('\\n'):\n",
    "        if line != '':\n",
    "            cw, cw_description = line.split('=')[0], line.split('=')[1]\n",
    "            cw_set.add(cw)\n",
    "            mapping[cw] = cw_description\n",
    "    return mapping, cw_set\n",
    "\n",
    "CW_MAPPING, CW_SET = build_chat_word_mapping(chat_words_str)\n",
    "\n",
    "def convert_chat_word(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.upper() in CW_SET:\n",
    "              new_text.append(CW_MAPPING[word.upper()])\n",
    "        else:\n",
    "              new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102876/102876 [00:00<00:00, 422718.84it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102876/102876 [00:00<00:00, 1158610.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102876/102876 [00:09<00:00, 10408.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102876/102876 [00:00<00:00, 201872.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102876/102876 [00:00<00:00, 140780.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#Applying cleaning methods.\n",
    "tqdm.pandas()\n",
    "df = remove_empty(df)\n",
    "df['reddit_text']= df['reddit_text'].progress_apply(remove_url) \n",
    "df['reddit_text']= df['reddit_text'].progress_apply(preprocess_text) \n",
    "df['reddit_text']= df['reddit_text'].progress_apply(remove_emoticons)\n",
    "df['reddit_text']= df['reddit_text'].progress_apply(remove_emoji)\n",
    "df['reddit_text']= df['reddit_text'].progress_apply(convert_chat_word)\n",
    "df = remove_empty(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98823</th>\n",
       "      <td>i did! i got a CJO</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27093</th>\n",
       "      <td>How'd it go?</td>\n",
       "      <td>Chase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18322</th>\n",
       "      <td>Good question. Work on that resume just in cas...</td>\n",
       "      <td>RiteAid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34887</th>\n",
       "      <td>I know someone aged 55 who got a job offer thi...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38421</th>\n",
       "      <td>I understand that question if you work in a ca...</td>\n",
       "      <td>TalesFromYourBank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58329</th>\n",
       "      <td>No, do not use your account number for anythin...</td>\n",
       "      <td>TalesFromYourBank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51432</th>\n",
       "      <td>Just a simple question for me to clarify. Can ...</td>\n",
       "      <td>KrakenSupport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61105</th>\n",
       "      <td>Oh, u got fired from Frontier- I am sure there...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29235</th>\n",
       "      <td>I checked my support history. It shows no acti...</td>\n",
       "      <td>KrakenSupport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100758</th>\n",
       "      <td>so funny you say this when last night the part...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53102</th>\n",
       "      <td>Likewise‚Ä¶ I felt that way with my first airlin...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25362</th>\n",
       "      <td>Hi! Washington here, THC is legalized. I appli...</td>\n",
       "      <td>RiteAid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39310</th>\n",
       "      <td>I was looking at his gallery, goes further tha...</td>\n",
       "      <td>TalesFromYourBank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>Congratulation!! Which language do you speak? ...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20334</th>\n",
       "      <td>Hello all,I have a f2f with American Airlines ...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>25 cents after two years</td>\n",
       "      <td>PaneraEmployees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61762</th>\n",
       "      <td>Old money, obviously.And one very new penny fo...</td>\n",
       "      <td>TalesFromYourBank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16403</th>\n",
       "      <td>First years are averaging like 50k/yr. Calling...</td>\n",
       "      <td>cabincrewcareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55120</th>\n",
       "      <td>Mmm, yes. Bankers insisting bankers aren't up ...</td>\n",
       "      <td>Chase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>Really? Wow that's great to hear. I had a pret...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reddit_text   reddit_subreddit\n",
       "98823                                  i did! i got a CJO   cabincrewcareers\n",
       "27093                                        How'd it go?              Chase\n",
       "18322   Good question. Work on that resume just in cas...            RiteAid\n",
       "34887   I know someone aged 55 who got a job offer thi...   cabincrewcareers\n",
       "38421   I understand that question if you work in a ca...  TalesFromYourBank\n",
       "58329   No, do not use your account number for anythin...  TalesFromYourBank\n",
       "51432   Just a simple question for me to clarify. Can ...      KrakenSupport\n",
       "61105   Oh, u got fired from Frontier- I am sure there...   cabincrewcareers\n",
       "29235   I checked my support history. It shows no acti...      KrakenSupport\n",
       "100758  so funny you say this when last night the part...   cabincrewcareers\n",
       "53102   Likewise‚Ä¶ I felt that way with my first airlin...   cabincrewcareers\n",
       "25362   Hi! Washington here, THC is legalized. I appli...            RiteAid\n",
       "39310   I was looking at his gallery, goes further tha...  TalesFromYourBank\n",
       "10911   Congratulation!! Which language do you speak? ...   cabincrewcareers\n",
       "20334   Hello all,I have a f2f with American Airlines ...   cabincrewcareers\n",
       "1283                             25 cents after two years    PaneraEmployees\n",
       "61762   Old money, obviously.And one very new penny fo...  TalesFromYourBank\n",
       "16403   First years are averaging like 50k/yr. Calling...   cabincrewcareers\n",
       "55120   Mmm, yes. Bankers insisting bankers aren't up ...              Chase\n",
       "64794   Really? Wow that's great to hear. I had a pret...     BestBuyWorkers"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving cleaned data for potential future use\n",
    "df.to_csv('processeddata.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using SBERT to rank the reddit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining SBERT model for generating sentence embeddings\n",
    "sentence_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    if not text.strip(): \n",
    "    #.strip() gets rid of new lines\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = sentence_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()\n",
    "\n",
    "def cos_angle(v, w): \n",
    "#inputs v, w are vectors in 1-dimensional tensors (np.array(list))\n",
    "    v = v.reshape(1,-1)\n",
    "    w = w.reshape(1,-1)\n",
    "    return cosine_similarity(v, w)\n",
    "\n",
    "def inn(v, w):\n",
    "    return v @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:10<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# loading or generating embeddings\n",
    "embedding_results = []\n",
    "\n",
    "for col in tqdm(selected_subreddts, position=1):\n",
    "    dfcol = df[df['reddit_subreddit']==col]\n",
    "    dfcol = dfcol.sort_values(by='reddit_text') # sort them by reddit texts\n",
    "    dfcol = dfcol.reset_index().drop(columns='index') # resetting indices\n",
    "    if os.path.exists(col+'_embeddings.pt'):\n",
    "        textembedding = torch.load(col + '_embeddings.pt')\n",
    "        dfcol = dfcol.assign(textembedding = textembedding)\n",
    "    else:\n",
    "        textembedding = [get_sentence_embedding(x) for x in tqdm(dfcol['reddit_text'], position=0)] #compute sentence embeddings\n",
    "        torch.save(textembedding, col + '_embeddings.pt') #save embeddings for potential use later\n",
    "        dfcol = dfcol.assign(textembedding = textembedding)\n",
    "        dfcol.to_csv(col+'.csv', index=True) #save dataframe for potential use later\n",
    "    \n",
    "    d = {\n",
    "    \"subreddit\": col,\n",
    "    \"dataframe\": dfcol,\n",
    "    \"average_embedding\": np.average(textembedding,axis = 0)}\n",
    "    \n",
    "    embedding_results.append(d)\n",
    "    \n",
    "db = pd.DataFrame(embedding_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>average_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TalesFromYourBank</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.005197360952537699, -0.006250292531688477,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cabincrewcareers</td>\n",
       "      <td>r...</td>\n",
       "      <td>[0.00043171990228924506, -0.005137783052966276...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chase</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.011372712559842126, -0.0010401233618315545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KrakenSupport</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.0017264996006939439, -0.001783643988806693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.008500097343943296, -0.00248342203242274, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.005873798435248916, -0.0051915133856321564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RiteAid</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.0054854856773563125, -0.002291048301678379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PaneraEmployees</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.006839217325948276, -0.0024444137202842757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>red...</td>\n",
       "      <td>[-0.0045604230282108235, -0.006909224058766821...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit                                          dataframe  \\\n",
       "0  TalesFromYourBank                                               r...   \n",
       "1   cabincrewcareers                                               r...   \n",
       "2              Chase                                               r...   \n",
       "3      KrakenSupport                                               r...   \n",
       "4   WalmartEmployees                                               r...   \n",
       "5     BestBuyWorkers                                              re...   \n",
       "6            RiteAid                                              re...   \n",
       "7    PaneraEmployees                                              re...   \n",
       "8       FedEmployees                                             red...   \n",
       "\n",
       "                                   average_embedding  \n",
       "0  [-0.005197360952537699, -0.006250292531688477,...  \n",
       "1  [0.00043171990228924506, -0.005137783052966276...  \n",
       "2  [-0.011372712559842126, -0.0010401233618315545...  \n",
       "3  [-0.0017264996006939439, -0.001783643988806693...  \n",
       "4  [-0.008500097343943296, -0.00248342203242274, ...  \n",
       "5  [-0.005873798435248916, -0.0051915133856321564...  \n",
       "6  [-0.0054854856773563125, -0.002291048301678379...  \n",
       "7  [-0.006839217325948276, -0.0024444137202842757...  \n",
       "8  [-0.0045604230282108235, -0.006909224058766821...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:27<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "clusterered_embeddings = []\n",
    "\n",
    "num_clusters = 4\n",
    "clustering_model = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "\n",
    "for col in tqdm(selected_subreddts):\n",
    "    dfcol = df[df['reddit_subreddit']==col]\n",
    "    dfcol = dfcol.sort_values(by='reddit_text') #sort them by reddit texts\n",
    "    dfcol = dfcol.reset_index().drop(columns='index') #resetting indices\n",
    "    \n",
    "    textembedding = torch.load(col + '_embeddings.pt')\n",
    "    dfcol = dfcol.assign(textembedding = textembedding) #create 'textembedding' column and store textembedding in it\n",
    "\n",
    "    X = preprocessing.normalize(textembedding)\n",
    "    clustering_model.fit(X)\n",
    "    dfcol['Cluster ID'] = pd.Series(clustering_model.fit_predict(X))\n",
    "    \n",
    "    for i in range(num_clusters):\n",
    "        temp = dfcol[dfcol['Cluster ID'] == i]\n",
    "        d = {\n",
    "        \"subreddit\": col + '-Cluster' + str(i),\n",
    "        \"dataframe\": temp,\n",
    "        \"average_embedding\": np.average([x for x in temp['textembedding']], axis = 0)}\n",
    "        clusterered_embeddings.append(d)\n",
    "    \n",
    "    \n",
    "db_cluster = pd.DataFrame(clusterered_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>average_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TalesFromYourBank-Cluster0</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.0040272078714856715, -0.003254711372103259...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TalesFromYourBank-Cluster1</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.003341803076366174, -0.007956792389939725,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TalesFromYourBank-Cluster2</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.006795902141620346, -0.005613458560315768,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TalesFromYourBank-Cluster3</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.005708994377133483, -0.009339750569399848,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cabincrewcareers-Cluster0</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.008814253972035405, 0.0008850114829782974,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cabincrewcareers-Cluster1</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.0012390267438731216, -0.010243365836453102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cabincrewcareers-Cluster2</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.002012449527727655, -0.0032770080859143846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cabincrewcareers-Cluster3</td>\n",
       "      <td>r...</td>\n",
       "      <td>[0.008617801835901648, -0.005259758658647718, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chase-Cluster0</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.00861372841124063, -0.0026734423179895425,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chase-Cluster1</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.013078588633965708, -0.004586292042826056,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    subreddit  \\\n",
       "0  TalesFromYourBank-Cluster0   \n",
       "1  TalesFromYourBank-Cluster1   \n",
       "2  TalesFromYourBank-Cluster2   \n",
       "3  TalesFromYourBank-Cluster3   \n",
       "4   cabincrewcareers-Cluster0   \n",
       "5   cabincrewcareers-Cluster1   \n",
       "6   cabincrewcareers-Cluster2   \n",
       "7   cabincrewcareers-Cluster3   \n",
       "8              Chase-Cluster0   \n",
       "9              Chase-Cluster1   \n",
       "\n",
       "                                           dataframe  \\\n",
       "0                                               r...   \n",
       "1                                               r...   \n",
       "2                                               r...   \n",
       "3                                               r...   \n",
       "4                                               r...   \n",
       "5                                               r...   \n",
       "6                                               r...   \n",
       "7                                               r...   \n",
       "8                                               r...   \n",
       "9                                               r...   \n",
       "\n",
       "                                   average_embedding  \n",
       "0  [-0.0040272078714856715, -0.003254711372103259...  \n",
       "1  [-0.003341803076366174, -0.007956792389939725,...  \n",
       "2  [-0.006795902141620346, -0.005613458560315768,...  \n",
       "3  [-0.005708994377133483, -0.009339750569399848,...  \n",
       "4  [-0.008814253972035405, 0.0008850114829782974,...  \n",
       "5  [-0.0012390267438731216, -0.010243365836453102...  \n",
       "6  [-0.002012449527727655, -0.0032770080859143846...  \n",
       "7  [0.008617801835901648, -0.005259758658647718, ...  \n",
       "8  [-0.00861372841124063, -0.0026734423179895425,...  \n",
       "9  [-0.013078588633965708, -0.004586292042826056,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_cluster.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clusters: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of clusters: \" + str(len(db_cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cluster.to_csv('clustereddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many PTOs does a regular employee have a year?\"\n",
    "query_vector = get_sentence_embedding(query)\n",
    "query_vector = np.array(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>average_embedding</th>\n",
       "      <th>query_to_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>red...</td>\n",
       "      <td>[-0.0045604230282108235, -0.006909224058766821...</td>\n",
       "      <td>0.869348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.008500097343943296, -0.00248342203242274, ...</td>\n",
       "      <td>0.863571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.005873798435248916, -0.0051915133856321564...</td>\n",
       "      <td>0.860327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RiteAid</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.0054854856773563125, -0.002291048301678379...</td>\n",
       "      <td>0.857882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaneraEmployees</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.006839217325948276, -0.0024444137202842757...</td>\n",
       "      <td>0.853538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cabincrewcareers</td>\n",
       "      <td>r...</td>\n",
       "      <td>[0.00043171990228924506, -0.005137783052966276...</td>\n",
       "      <td>0.848919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TalesFromYourBank</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.005197360952537699, -0.006250292531688477,...</td>\n",
       "      <td>0.842512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chase</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.011372712559842126, -0.0010401233618315545...</td>\n",
       "      <td>0.820753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KrakenSupport</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.0017264996006939439, -0.001783643988806693...</td>\n",
       "      <td>0.800380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit                                          dataframe  \\\n",
       "0       FedEmployees                                             red...   \n",
       "1   WalmartEmployees                                               r...   \n",
       "2     BestBuyWorkers                                              re...   \n",
       "3            RiteAid                                              re...   \n",
       "4    PaneraEmployees                                              re...   \n",
       "5   cabincrewcareers                                               r...   \n",
       "6  TalesFromYourBank                                               r...   \n",
       "7              Chase                                               r...   \n",
       "8      KrakenSupport                                               r...   \n",
       "\n",
       "                                   average_embedding  query_to_average  \n",
       "0  [-0.0045604230282108235, -0.006909224058766821...          0.869348  \n",
       "1  [-0.008500097343943296, -0.00248342203242274, ...          0.863571  \n",
       "2  [-0.005873798435248916, -0.0051915133856321564...          0.860327  \n",
       "3  [-0.0054854856773563125, -0.002291048301678379...          0.857882  \n",
       "4  [-0.006839217325948276, -0.0024444137202842757...          0.853538  \n",
       "5  [0.00043171990228924506, -0.005137783052966276...          0.848919  \n",
       "6  [-0.005197360952537699, -0.006250292531688477,...          0.842512  \n",
       "7  [-0.011372712559842126, -0.0010401233618315545...          0.820753  \n",
       "8  [-0.0017264996006939439, -0.001783643988806693...          0.800380  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning average embedding and finding the closest subreddit -- create new col 'query_to_average' and then sort by the new column\n",
    "db = db.assign(query_to_average = [cos_angle(query_vector, x)[0][0] for x in db['average_embedding']]).sort_values('query_to_average', ascending = False) \n",
    "db = db.reset_index().drop(columns='index') #resetting indices\n",
    "db.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>average_embedding</th>\n",
       "      <th>query_to_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BestBuyWorkers-Cluster3</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.0025261466532921473, -0.007745908396475855...</td>\n",
       "      <td>0.880474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WalmartEmployees-Cluster0</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.005093428223200427, -0.000827104138358493,...</td>\n",
       "      <td>0.874014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RiteAid-Cluster1</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.0034636042534133145, -0.007548518882219773...</td>\n",
       "      <td>0.872972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedEmployees-Cluster1</td>\n",
       "      <td>red...</td>\n",
       "      <td>[-0.003005605609307194, -0.014883679618082091,...</td>\n",
       "      <td>0.866990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaneraEmployees-Cluster0</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.002430848551148892, -0.004593826097116363,...</td>\n",
       "      <td>0.866774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FedEmployees-Cluster2</td>\n",
       "      <td>red...</td>\n",
       "      <td>[-0.0019716562598081177, 0.00415739794698311, ...</td>\n",
       "      <td>0.862142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WalmartEmployees-Cluster1</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.01105996694646753, -0.0014071418133920317,...</td>\n",
       "      <td>0.857107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BestBuyWorkers-Cluster1</td>\n",
       "      <td>re...</td>\n",
       "      <td>[-0.002131252957801869, -0.007079905009041493,...</td>\n",
       "      <td>0.856871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TalesFromYourBank-Cluster1</td>\n",
       "      <td>r...</td>\n",
       "      <td>[-0.003341803076366174, -0.007956792389939725,...</td>\n",
       "      <td>0.849788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FedEmployees-Cluster3</td>\n",
       "      <td>red...</td>\n",
       "      <td>[-0.008685157023137435, -0.004481811649621586,...</td>\n",
       "      <td>0.848829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    subreddit  \\\n",
       "0     BestBuyWorkers-Cluster3   \n",
       "1   WalmartEmployees-Cluster0   \n",
       "2            RiteAid-Cluster1   \n",
       "3       FedEmployees-Cluster1   \n",
       "4    PaneraEmployees-Cluster0   \n",
       "5       FedEmployees-Cluster2   \n",
       "6   WalmartEmployees-Cluster1   \n",
       "7     BestBuyWorkers-Cluster1   \n",
       "8  TalesFromYourBank-Cluster1   \n",
       "9       FedEmployees-Cluster3   \n",
       "\n",
       "                                           dataframe  \\\n",
       "0                                              re...   \n",
       "1                                               r...   \n",
       "2                                              re...   \n",
       "3                                             red...   \n",
       "4                                              re...   \n",
       "5                                             red...   \n",
       "6                                               r...   \n",
       "7                                              re...   \n",
       "8                                               r...   \n",
       "9                                             red...   \n",
       "\n",
       "                                   average_embedding  query_to_average  \n",
       "0  [-0.0025261466532921473, -0.007745908396475855...          0.880474  \n",
       "1  [-0.005093428223200427, -0.000827104138358493,...          0.874014  \n",
       "2  [-0.0034636042534133145, -0.007548518882219773...          0.872972  \n",
       "3  [-0.003005605609307194, -0.014883679618082091,...          0.866990  \n",
       "4  [-0.002430848551148892, -0.004593826097116363,...          0.866774  \n",
       "5  [-0.0019716562598081177, 0.00415739794698311, ...          0.862142  \n",
       "6  [-0.01105996694646753, -0.0014071418133920317,...          0.857107  \n",
       "7  [-0.002131252957801869, -0.007079905009041493,...          0.856871  \n",
       "8  [-0.003341803076366174, -0.007956792389939725,...          0.849788  \n",
       "9  [-0.008685157023137435, -0.004481811649621586,...          0.848829  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning average embedding to each cluster and finding the closest clusters\n",
    "db_cluster = db_cluster.assign(query_to_average = [cos_angle(query_vector, x)[0][0] for x in db_cluster['average_embedding']]).sort_values('query_to_average', ascending = False)\n",
    "db_cluster = db_cluster.reset_index().drop(columns='index') #resetting indices\n",
    "db_cluster.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Personal Investment Performance (PIP** - The...</td>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>[-0.02338474802672863, -0.0011061999248340726,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**[More Lifecycle Funds will be available July...</td>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>[0.009730241261422634, 0.012903322465717793, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/CH1EFK1NGD0M, I have found an error in your...</td>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>[-0.0019741507712751627, -0.02949591539800167,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yr from date you started the position in that...</td>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>[-0.011592128314077854, 0.018938761204481125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21% gains</td>\n",
       "      <td>FedEmployees</td>\n",
       "      <td>[-0.0038938489742577076, 0.027892155572772026,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>‚ÄúWho are you to deny the return of the PS5 box...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.008801989257335663, -0.010793385095894337,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>‚Äúthe narrative‚Äù Lmao or it‚Äôs just likely that ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.008601270616054535, -0.021344924345612526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>‚Ä¶ yes? Are you one of the programmers did I hu...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.02130361832678318, -0.017897486686706543, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>ü§£ü§£ thank you for the advice. Mind elaborating ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.00029987579910084605, 0.002727767685428261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>ü§£ü§£ü§£ü§£ü§£ü§£</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.013457155786454678, -0.0022745642345398664...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15785 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reddit_text reddit_subreddit  \\\n",
       "0     **Personal Investment Performance (PIP** - The...     FedEmployees   \n",
       "1     **[More Lifecycle Funds will be available July...     FedEmployees   \n",
       "2     /u/CH1EFK1NGD0M, I have found an error in your...     FedEmployees   \n",
       "3     1yr from date you started the position in that...     FedEmployees   \n",
       "4                                             21% gains     FedEmployees   \n",
       "...                                                 ...              ...   \n",
       "5368  ‚ÄúWho are you to deny the return of the PS5 box...   BestBuyWorkers   \n",
       "5369  ‚Äúthe narrative‚Äù Lmao or it‚Äôs just likely that ...   BestBuyWorkers   \n",
       "5370  ‚Ä¶ yes? Are you one of the programmers did I hu...   BestBuyWorkers   \n",
       "5371  ü§£ü§£ thank you for the advice. Mind elaborating ...   BestBuyWorkers   \n",
       "5372                                             ü§£ü§£ü§£ü§£ü§£ü§£   BestBuyWorkers   \n",
       "\n",
       "                                          textembedding  \n",
       "0     [-0.02338474802672863, -0.0011061999248340726,...  \n",
       "1     [0.009730241261422634, 0.012903322465717793, -...  \n",
       "2     [-0.0019741507712751627, -0.02949591539800167,...  \n",
       "3     [-0.011592128314077854, 0.018938761204481125, ...  \n",
       "4     [-0.0038938489742577076, 0.027892155572772026,...  \n",
       "...                                                 ...  \n",
       "5368  [-0.008801989257335663, -0.010793385095894337,...  \n",
       "5369  [-0.008601270616054535, -0.021344924345612526,...  \n",
       "5370  [0.02130361832678318, -0.017897486686706543, -...  \n",
       "5371  [-0.00029987579910084605, 0.002727767685428261...  \n",
       "5372  [-0.013457155786454678, -0.0022745642345398664...  \n",
       "\n",
       "[15785 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_nocluster = pd.concat([db.iloc[i].get('dataframe') for i in range(3)]) #top 3 subreddits\n",
    "df_bestmatch_nocluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "      <th>Cluster ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Anonymous\", sorry to give you the bad news bu...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.007506015244871378, -0.014071070589125156,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>. It‚Äôs also still annually when you would norm...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.012578140012919903, -0.013978547416627407,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>...Shift-leads, how does the differential refl...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.017350517213344574, 0.008666640147566795, -...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1 You‚Äôre a douchebag if you think people who w...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.026971837505698204, 0.009699751622974873, -...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100% agree and I think the CIA position is nic...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.003729616291821003, -0.01914779655635357, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>why did they schedule it when you were away on...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.0024575316347181797, -0.002191046252846718...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>yeah just signed an offer and had to take one ...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.012678598053753376, -0.02642296813428402, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>yeah we didn‚Äôt get paid either</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.006170068401843309, -0.011933591216802597,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>yup the micromanaging has what‚Äôs annoyed me th...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.013876966200768948, -0.023693732917308807, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>‚ÄúPTO will not be paid out upon termination unl...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.026494866237044334, -0.02763434499502182, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4706 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reddit_text reddit_subreddit  \\\n",
       "16    \"Anonymous\", sorry to give you the bad news bu...   BestBuyWorkers   \n",
       "50    . It‚Äôs also still annually when you would norm...   BestBuyWorkers   \n",
       "51    ...Shift-leads, how does the differential refl...   BestBuyWorkers   \n",
       "57    1 You‚Äôre a douchebag if you think people who w...   BestBuyWorkers   \n",
       "68    100% agree and I think the CIA position is nic...   BestBuyWorkers   \n",
       "...                                                 ...              ...   \n",
       "3654  why did they schedule it when you were away on...          RiteAid   \n",
       "3658  yeah just signed an offer and had to take one ...          RiteAid   \n",
       "3660                     yeah we didn‚Äôt get paid either          RiteAid   \n",
       "3668  yup the micromanaging has what‚Äôs annoyed me th...          RiteAid   \n",
       "3672  ‚ÄúPTO will not be paid out upon termination unl...          RiteAid   \n",
       "\n",
       "                                          textembedding  Cluster ID  \n",
       "16    [-0.007506015244871378, -0.014071070589125156,...           3  \n",
       "50    [-0.012578140012919903, -0.013978547416627407,...           3  \n",
       "51    [0.017350517213344574, 0.008666640147566795, -...           3  \n",
       "57    [0.026971837505698204, 0.009699751622974873, -...           3  \n",
       "68    [-0.003729616291821003, -0.01914779655635357, ...           3  \n",
       "...                                                 ...         ...  \n",
       "3654  [-0.0024575316347181797, -0.002191046252846718...           1  \n",
       "3658  [-0.012678598053753376, -0.02642296813428402, ...           1  \n",
       "3660  [-0.006170068401843309, -0.011933591216802597,...           1  \n",
       "3668  [0.013876966200768948, -0.023693732917308807, ...           1  \n",
       "3672  [-0.026494866237044334, -0.02763434499502182, ...           1  \n",
       "\n",
       "[4706 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_cluster = pd.concat([db_cluster.iloc[i].get('dataframe') for i in range(3)]) #top 3 clusters\n",
    "df_bestmatch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without clustering, the runtime is over 1s\n",
    "df_bestmatch_nocluster = df_bestmatch_nocluster.assign(cos_angles = [cos_angle(query_vector, np.array(x))[0][0] for x in df_bestmatch_nocluster['textembedding']]).sort_values('cos_angles', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "      <th>cos_angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>Not sure about PTO, but the most ppto you can ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.017012763768434525, 0.001875273184850812, ...</td>\n",
       "      <td>0.881989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>All associates earn PPTO, which is intended fo...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.022059394046664238, -0.0017816615290939808...</td>\n",
       "      <td>0.879523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Full timers generally earn pto faster. But mos...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008347814902663231, 0.010986099019646645, ...</td>\n",
       "      <td>0.879252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>Just went through onboarding (for Walmart dist...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0019015533616766334, -0.009029080159962177...</td>\n",
       "      <td>0.878480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>I get 21 mins of ppto earned per shift (10 hrs...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.003536654869094491, 0.007027565501630306, -...</td>\n",
       "      <td>0.877869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>It is like pto</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.017847731709480286, -0.02621033973991871, ...</td>\n",
       "      <td>0.877719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>Yeah I'm aware of the benefits and pto. I just...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.004729983396828175, -0.006030685734003782, ...</td>\n",
       "      <td>0.876310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>Most places I've seen typically provide 0 PTO ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.013062798418104649, -0.016060488298535347,...</td>\n",
       "      <td>0.875701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>Not everyone gets ppto at the same rate. You s...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008390921168029308, 0.01311011053621769, -...</td>\n",
       "      <td>0.874638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>overtime, bonuses, PTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038837369065731764, -0.01123464573174715,...</td>\n",
       "      <td>0.873787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>How the hell do they Calculate PTO? Cause, at ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02035108581185341, -0.006431127432733774, ...</td>\n",
       "      <td>0.872277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>You‚Äôll get pto either once you become full tim...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02038499154150486, -0.017435207962989807, ...</td>\n",
       "      <td>0.866943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>It is not a month if pto bro when you first ge...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.0026660107541829348, -0.008649304509162903,...</td>\n",
       "      <td>0.864908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>Planning a walkout across the US for a minimum...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038310568779706955, -0.011676630936563015...</td>\n",
       "      <td>0.864450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.00 = one hour.So you have almost an hour of ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.010056194849312305, 0.01743551343679428, -0...</td>\n",
       "      <td>0.863413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>**Regular PTO is for scheduled absences.** Use...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.00952619593590498, -0.012450425885617733, ...</td>\n",
       "      <td>0.862565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>Idk if I have PTO or PPTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.01904052495956421, -0.04282870888710022, -...</td>\n",
       "      <td>0.862428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>Only paid of you use your pto</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0014362988295033574, -0.022054068744182587...</td>\n",
       "      <td>0.861380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6660</th>\n",
       "      <td>So it hasn‚Äôt changed for the vast majority of ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.006396268494427204, -0.0003179972118232399,...</td>\n",
       "      <td>0.860976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>PTO should get paid out‚Ä¶</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.002405428094789386, -0.021997543051838875, ...</td>\n",
       "      <td>0.858364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reddit_text  reddit_subreddit  \\\n",
       "5678   Not sure about PTO, but the most ppto you can ...  WalmartEmployees   \n",
       "301    All associates earn PPTO, which is intended fo...  WalmartEmployees   \n",
       "1619   Full timers generally earn pto faster. But mos...  WalmartEmployees   \n",
       "4867   Just went through onboarding (for Walmart dist...  WalmartEmployees   \n",
       "2620   I get 21 mins of ppto earned per shift (10 hrs...  WalmartEmployees   \n",
       "2275                                      It is like pto    BestBuyWorkers   \n",
       "8914   Yeah I'm aware of the benefits and pto. I just...  WalmartEmployees   \n",
       "2811   Most places I've seen typically provide 0 PTO ...    BestBuyWorkers   \n",
       "5655   Not everyone gets ppto at the same rate. You s...  WalmartEmployees   \n",
       "10041                             overtime, bonuses, PTO  WalmartEmployees   \n",
       "2227   How the hell do they Calculate PTO? Cause, at ...  WalmartEmployees   \n",
       "9658   You‚Äôll get pto either once you become full tim...  WalmartEmployees   \n",
       "2276   It is not a month if pto bro when you first ge...    BestBuyWorkers   \n",
       "6154   Planning a walkout across the US for a minimum...  WalmartEmployees   \n",
       "80     1.00 = one hour.So you have almost an hour of ...  WalmartEmployees   \n",
       "39     **Regular PTO is for scheduled absences.** Use...  WalmartEmployees   \n",
       "3783                           Idk if I have PTO or PPTO  WalmartEmployees   \n",
       "6000                       Only paid of you use your pto  WalmartEmployees   \n",
       "6660   So it hasn‚Äôt changed for the vast majority of ...  WalmartEmployees   \n",
       "3213                            PTO should get paid out‚Ä¶    BestBuyWorkers   \n",
       "\n",
       "                                           textembedding  cos_angles  \n",
       "5678   [-0.017012763768434525, 0.001875273184850812, ...    0.881989  \n",
       "301    [-0.022059394046664238, -0.0017816615290939808...    0.879523  \n",
       "1619   [-0.008347814902663231, 0.010986099019646645, ...    0.879252  \n",
       "4867   [-0.0019015533616766334, -0.009029080159962177...    0.878480  \n",
       "2620   [0.003536654869094491, 0.007027565501630306, -...    0.877869  \n",
       "2275   [-0.017847731709480286, -0.02621033973991871, ...    0.877719  \n",
       "8914   [0.004729983396828175, -0.006030685734003782, ...    0.876310  \n",
       "2811   [-0.013062798418104649, -0.016060488298535347,...    0.875701  \n",
       "5655   [-0.008390921168029308, 0.01311011053621769, -...    0.874638  \n",
       "10041  [-0.0038837369065731764, -0.01123464573174715,...    0.873787  \n",
       "2227   [-0.02035108581185341, -0.006431127432733774, ...    0.872277  \n",
       "9658   [-0.02038499154150486, -0.017435207962989807, ...    0.866943  \n",
       "2276   [0.0026660107541829348, -0.008649304509162903,...    0.864908  \n",
       "6154   [-0.0038310568779706955, -0.011676630936563015...    0.864450  \n",
       "80     [0.010056194849312305, 0.01743551343679428, -0...    0.863413  \n",
       "39     [-0.00952619593590498, -0.012450425885617733, ...    0.862565  \n",
       "3783   [-0.01904052495956421, -0.04282870888710022, -...    0.862428  \n",
       "6000   [-0.0014362988295033574, -0.022054068744182587...    0.861380  \n",
       "6660   [0.006396268494427204, -0.0003179972118232399,...    0.860976  \n",
       "3213   [0.002405428094789386, -0.021997543051838875, ...    0.858364  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_nocluster.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By clustering, we cut down our runtown to under 1s \n",
    "df_bestmatch_cluster = df_bestmatch_cluster.assign(cos_angles = [cos_angle(query_vector, np.array(x))[0][0] for x in df_bestmatch_cluster['textembedding']]).sort_values('cos_angles', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>cos_angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>Not sure about PTO, but the most ppto you can ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.017012763768434525, 0.001875273184850812, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>All associates earn PPTO, which is intended fo...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.022059394046664238, -0.0017816615290939808...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Full timers generally earn pto faster. But mos...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008347814902663231, 0.010986099019646645, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>Just went through onboarding (for Walmart dist...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0019015533616766334, -0.009029080159962177...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>I get 21 mins of ppto earned per shift (10 hrs...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.003536654869094491, 0.007027565501630306, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>It is like pto</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.017847731709480286, -0.02621033973991871, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.877719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>Yeah I'm aware of the benefits and pto. I just...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.004729983396828175, -0.006030685734003782, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>Most places I've seen typically provide 0 PTO ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.013062798418104649, -0.016060488298535347,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>Not everyone gets ppto at the same rate. You s...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008390921168029308, 0.01311011053621769, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>overtime, bonuses, PTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038837369065731764, -0.01123464573174715,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>How the hell do they Calculate PTO? Cause, at ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02035108581185341, -0.006431127432733774, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Depends on your state. Look up PTO in the hub....</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.02337043359875679, -0.034504592418670654, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>You‚Äôll get pto either once you become full tim...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02038499154150486, -0.017435207962989807, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>It varies greatly by state/location and store ...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.0023047644644975662, 0.0036134349647909403,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>It is not a month if pto bro when you first ge...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.0026660107541829348, -0.008649304509162903,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>Planning a walkout across the US for a minimum...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038310568779706955, -0.011676630936563015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.00 = one hour.So you have almost an hour of ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.010056194849312305, 0.01743551343679428, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>**Regular PTO is for scheduled absences.** Use...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.00952619593590498, -0.012450425885617733, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>Idk if I have PTO or PPTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.01904052495956421, -0.04282870888710022, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>Only paid of you use your pto</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0014362988295033574, -0.022054068744182587...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reddit_text  reddit_subreddit  \\\n",
       "5678   Not sure about PTO, but the most ppto you can ...  WalmartEmployees   \n",
       "301    All associates earn PPTO, which is intended fo...  WalmartEmployees   \n",
       "1619   Full timers generally earn pto faster. But mos...  WalmartEmployees   \n",
       "4867   Just went through onboarding (for Walmart dist...  WalmartEmployees   \n",
       "2620   I get 21 mins of ppto earned per shift (10 hrs...  WalmartEmployees   \n",
       "2275                                      It is like pto    BestBuyWorkers   \n",
       "8914   Yeah I'm aware of the benefits and pto. I just...  WalmartEmployees   \n",
       "2811   Most places I've seen typically provide 0 PTO ...    BestBuyWorkers   \n",
       "5655   Not everyone gets ppto at the same rate. You s...  WalmartEmployees   \n",
       "10041                             overtime, bonuses, PTO  WalmartEmployees   \n",
       "2227   How the hell do they Calculate PTO? Cause, at ...  WalmartEmployees   \n",
       "471    Depends on your state. Look up PTO in the hub....           RiteAid   \n",
       "9658   You‚Äôll get pto either once you become full tim...  WalmartEmployees   \n",
       "1517   It varies greatly by state/location and store ...           RiteAid   \n",
       "2276   It is not a month if pto bro when you first ge...    BestBuyWorkers   \n",
       "6154   Planning a walkout across the US for a minimum...  WalmartEmployees   \n",
       "80     1.00 = one hour.So you have almost an hour of ...  WalmartEmployees   \n",
       "39     **Regular PTO is for scheduled absences.** Use...  WalmartEmployees   \n",
       "3783                           Idk if I have PTO or PPTO  WalmartEmployees   \n",
       "6000                       Only paid of you use your pto  WalmartEmployees   \n",
       "\n",
       "                                           textembedding  Cluster ID  \\\n",
       "5678   [-0.017012763768434525, 0.001875273184850812, ...           0   \n",
       "301    [-0.022059394046664238, -0.0017816615290939808...           0   \n",
       "1619   [-0.008347814902663231, 0.010986099019646645, ...           0   \n",
       "4867   [-0.0019015533616766334, -0.009029080159962177...           0   \n",
       "2620   [0.003536654869094491, 0.007027565501630306, -...           0   \n",
       "2275   [-0.017847731709480286, -0.02621033973991871, ...           3   \n",
       "8914   [0.004729983396828175, -0.006030685734003782, ...           0   \n",
       "2811   [-0.013062798418104649, -0.016060488298535347,...           3   \n",
       "5655   [-0.008390921168029308, 0.01311011053621769, -...           0   \n",
       "10041  [-0.0038837369065731764, -0.01123464573174715,...           0   \n",
       "2227   [-0.02035108581185341, -0.006431127432733774, ...           0   \n",
       "471    [-0.02337043359875679, -0.034504592418670654, ...           1   \n",
       "9658   [-0.02038499154150486, -0.017435207962989807, ...           0   \n",
       "1517   [0.0023047644644975662, 0.0036134349647909403,...           1   \n",
       "2276   [0.0026660107541829348, -0.008649304509162903,...           3   \n",
       "6154   [-0.0038310568779706955, -0.011676630936563015...           0   \n",
       "80     [0.010056194849312305, 0.01743551343679428, -0...           0   \n",
       "39     [-0.00952619593590498, -0.012450425885617733, ...           0   \n",
       "3783   [-0.01904052495956421, -0.04282870888710022, -...           0   \n",
       "6000   [-0.0014362988295033574, -0.022054068744182587...           0   \n",
       "\n",
       "       cos_angles  \n",
       "5678     0.881989  \n",
       "301      0.879523  \n",
       "1619     0.879252  \n",
       "4867     0.878480  \n",
       "2620     0.877869  \n",
       "2275     0.877719  \n",
       "8914     0.876310  \n",
       "2811     0.875701  \n",
       "5655     0.874638  \n",
       "10041    0.873787  \n",
       "2227     0.872277  \n",
       "471      0.867577  \n",
       "9658     0.866943  \n",
       "1517     0.866713  \n",
       "2276     0.864908  \n",
       "6154     0.864450  \n",
       "80       0.863413  \n",
       "39       0.862565  \n",
       "3783     0.862428  \n",
       "6000     0.861380  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_cluster.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improving performance via synthetic query generation and averaging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query:\n",
      "How many PTOs does a regular employee have a year?\n",
      "\n",
      "Generated Synthetic Queries:\n",
      "1: how many pto hours do employees earn\n",
      "2: how many pto hours do regular employees get\n",
      "3: how many hours of pto can an employee earn\n"
     ]
    }
   ],
   "source": [
    "#We generate synethetic queries to help improve the performance of our model \n",
    "input = tokenizer.encode(query, return_tensors='pt')\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input,\n",
    "    max_length=16,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3)\n",
    "\n",
    "print(\"Original query:\")\n",
    "\n",
    "print(query)\n",
    "\n",
    "print(\"\\nGenerated Synthetic Queries:\")\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    q = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "    print(f'{i + 1}: {q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_query_vectors = [get_sentence_embedding(tokenizer.decode(x, skip_special_tokens=True)) for x in outputs]\n",
    "chosen_query_vectors.append(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cos_angles = []\n",
    "\n",
    "for x in df_bestmatch_cluster['textembedding']:\n",
    "    avg_cos_angle = 0\n",
    "    for v in chosen_query_vectors:\n",
    "        avg_cos_angle += cos_angle(np.array(v), np.array(x))[0][0]\n",
    "    avg_cos_angles.append(avg_cos_angle/len(chosen_query_vectors))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bestmatch_cluster = df_bestmatch_cluster.assign(avg_cos_angles = avg_cos_angles).sort_values('cos_angles', ascending = False)\n",
    "df_bestmatch_by_avg = df_bestmatch_cluster.assign(avg_cos_angles = avg_cos_angles).sort_values('avg_cos_angles', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>cos_angles</th>\n",
       "      <th>avg_cos_angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>Not sure about PTO, but the most ppto you can ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.017012763768434525, 0.001875273184850812, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881989</td>\n",
       "      <td>0.909629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>All associates earn PPTO, which is intended fo...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.022059394046664238, -0.0017816615290939808...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879523</td>\n",
       "      <td>0.891735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Full timers generally earn pto faster. But mos...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008347814902663231, 0.010986099019646645, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879252</td>\n",
       "      <td>0.899054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>Just went through onboarding (for Walmart dist...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0019015533616766334, -0.009029080159962177...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878480</td>\n",
       "      <td>0.882403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>I get 21 mins of ppto earned per shift (10 hrs...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.003536654869094491, 0.007027565501630306, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877869</td>\n",
       "      <td>0.904211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>It is like pto</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.017847731709480286, -0.02621033973991871, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.877719</td>\n",
       "      <td>0.872764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>Yeah I'm aware of the benefits and pto. I just...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.004729983396828175, -0.006030685734003782, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876310</td>\n",
       "      <td>0.873622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>Most places I've seen typically provide 0 PTO ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.013062798418104649, -0.016060488298535347,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875701</td>\n",
       "      <td>0.868772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>Not everyone gets ppto at the same rate. You s...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008390921168029308, 0.01311011053621769, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.899730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>overtime, bonuses, PTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038837369065731764, -0.01123464573174715,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873787</td>\n",
       "      <td>0.888385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>How the hell do they Calculate PTO? Cause, at ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02035108581185341, -0.006431127432733774, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872277</td>\n",
       "      <td>0.875250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Depends on your state. Look up PTO in the hub....</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[-0.02337043359875679, -0.034504592418670654, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867577</td>\n",
       "      <td>0.870957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9658</th>\n",
       "      <td>You‚Äôll get pto either once you become full tim...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02038499154150486, -0.017435207962989807, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866943</td>\n",
       "      <td>0.858920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>It varies greatly by state/location and store ...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.0023047644644975662, 0.0036134349647909403,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866713</td>\n",
       "      <td>0.888629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>It is not a month if pto bro when you first ge...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.0026660107541829348, -0.008649304509162903,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864908</td>\n",
       "      <td>0.884134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>Planning a walkout across the US for a minimum...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038310568779706955, -0.011676630936563015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864450</td>\n",
       "      <td>0.860912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.00 = one hour.So you have almost an hour of ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.010056194849312305, 0.01743551343679428, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863413</td>\n",
       "      <td>0.885810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>**Regular PTO is for scheduled absences.** Use...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.00952619593590498, -0.012450425885617733, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862565</td>\n",
       "      <td>0.852364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>Idk if I have PTO or PPTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.01904052495956421, -0.04282870888710022, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862428</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>Only paid of you use your pto</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0014362988295033574, -0.022054068744182587...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.876210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reddit_text  reddit_subreddit  \\\n",
       "5678   Not sure about PTO, but the most ppto you can ...  WalmartEmployees   \n",
       "301    All associates earn PPTO, which is intended fo...  WalmartEmployees   \n",
       "1619   Full timers generally earn pto faster. But mos...  WalmartEmployees   \n",
       "4867   Just went through onboarding (for Walmart dist...  WalmartEmployees   \n",
       "2620   I get 21 mins of ppto earned per shift (10 hrs...  WalmartEmployees   \n",
       "2275                                      It is like pto    BestBuyWorkers   \n",
       "8914   Yeah I'm aware of the benefits and pto. I just...  WalmartEmployees   \n",
       "2811   Most places I've seen typically provide 0 PTO ...    BestBuyWorkers   \n",
       "5655   Not everyone gets ppto at the same rate. You s...  WalmartEmployees   \n",
       "10041                             overtime, bonuses, PTO  WalmartEmployees   \n",
       "2227   How the hell do they Calculate PTO? Cause, at ...  WalmartEmployees   \n",
       "471    Depends on your state. Look up PTO in the hub....           RiteAid   \n",
       "9658   You‚Äôll get pto either once you become full tim...  WalmartEmployees   \n",
       "1517   It varies greatly by state/location and store ...           RiteAid   \n",
       "2276   It is not a month if pto bro when you first ge...    BestBuyWorkers   \n",
       "6154   Planning a walkout across the US for a minimum...  WalmartEmployees   \n",
       "80     1.00 = one hour.So you have almost an hour of ...  WalmartEmployees   \n",
       "39     **Regular PTO is for scheduled absences.** Use...  WalmartEmployees   \n",
       "3783                           Idk if I have PTO or PPTO  WalmartEmployees   \n",
       "6000                       Only paid of you use your pto  WalmartEmployees   \n",
       "\n",
       "                                           textembedding  Cluster ID  \\\n",
       "5678   [-0.017012763768434525, 0.001875273184850812, ...           0   \n",
       "301    [-0.022059394046664238, -0.0017816615290939808...           0   \n",
       "1619   [-0.008347814902663231, 0.010986099019646645, ...           0   \n",
       "4867   [-0.0019015533616766334, -0.009029080159962177...           0   \n",
       "2620   [0.003536654869094491, 0.007027565501630306, -...           0   \n",
       "2275   [-0.017847731709480286, -0.02621033973991871, ...           3   \n",
       "8914   [0.004729983396828175, -0.006030685734003782, ...           0   \n",
       "2811   [-0.013062798418104649, -0.016060488298535347,...           3   \n",
       "5655   [-0.008390921168029308, 0.01311011053621769, -...           0   \n",
       "10041  [-0.0038837369065731764, -0.01123464573174715,...           0   \n",
       "2227   [-0.02035108581185341, -0.006431127432733774, ...           0   \n",
       "471    [-0.02337043359875679, -0.034504592418670654, ...           1   \n",
       "9658   [-0.02038499154150486, -0.017435207962989807, ...           0   \n",
       "1517   [0.0023047644644975662, 0.0036134349647909403,...           1   \n",
       "2276   [0.0026660107541829348, -0.008649304509162903,...           3   \n",
       "6154   [-0.0038310568779706955, -0.011676630936563015...           0   \n",
       "80     [0.010056194849312305, 0.01743551343679428, -0...           0   \n",
       "39     [-0.00952619593590498, -0.012450425885617733, ...           0   \n",
       "3783   [-0.01904052495956421, -0.04282870888710022, -...           0   \n",
       "6000   [-0.0014362988295033574, -0.022054068744182587...           0   \n",
       "\n",
       "       cos_angles  avg_cos_angles  \n",
       "5678     0.881989        0.909629  \n",
       "301      0.879523        0.891735  \n",
       "1619     0.879252        0.899054  \n",
       "4867     0.878480        0.882403  \n",
       "2620     0.877869        0.904211  \n",
       "2275     0.877719        0.872764  \n",
       "8914     0.876310        0.873622  \n",
       "2811     0.875701        0.868772  \n",
       "5655     0.874638        0.899730  \n",
       "10041    0.873787        0.888385  \n",
       "2227     0.872277        0.875250  \n",
       "471      0.867577        0.870957  \n",
       "9658     0.866943        0.858920  \n",
       "1517     0.866713        0.888629  \n",
       "2276     0.864908        0.884134  \n",
       "6154     0.864450        0.860912  \n",
       "80       0.863413        0.885810  \n",
       "39       0.862565        0.852364  \n",
       "3783     0.862428        0.853145  \n",
       "6000     0.861380        0.876210  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_cluster.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>textembedding</th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>cos_angles</th>\n",
       "      <th>avg_cos_angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>Not sure about PTO, but the most ppto you can ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.017012763768434525, 0.001875273184850812, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881989</td>\n",
       "      <td>0.909629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>I get 21 mins of ppto earned per shift (10 hrs...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.003536654869094491, 0.007027565501630306, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877869</td>\n",
       "      <td>0.904211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>Not everyone gets ppto at the same rate. You s...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008390921168029308, 0.01311011053621769, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.899730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Full timers generally earn pto faster. But mos...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.008347814902663231, 0.010986099019646645, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879252</td>\n",
       "      <td>0.899054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>All associates earn PPTO, which is intended fo...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.022059394046664238, -0.0017816615290939808...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879523</td>\n",
       "      <td>0.891735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>It varies greatly by state/location and store ...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.0023047644644975662, 0.0036134349647909403,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866713</td>\n",
       "      <td>0.888629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>overtime, bonuses, PTO</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0038837369065731764, -0.01123464573174715,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873787</td>\n",
       "      <td>0.888385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.00 = one hour.So you have almost an hour of ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[0.010056194849312305, 0.01743551343679428, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863413</td>\n",
       "      <td>0.885810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>I was just remembering earlier that it‚Äôs suppo...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.00040522910421714187, 0.007721611764281988...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857598</td>\n",
       "      <td>0.885746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>It is not a month if pto bro when you first ge...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.0026660107541829348, -0.008649304509162903,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864908</td>\n",
       "      <td>0.884134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>So they paid you slightly less per hour then t...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0011713088024407625, -0.010902976617217064...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852667</td>\n",
       "      <td>0.882879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>Just went through onboarding (for Walmart dist...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0019015533616766334, -0.009029080159962177...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878480</td>\n",
       "      <td>0.882403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>In CA they paid out my 400 hours of PTO.</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.0038649067282676697, -0.01133443508297205, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851739</td>\n",
       "      <td>0.880104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Hours cut to 32 hrs a week again for me too fo...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.005697236862033606, 0.002120997989550233, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.855249</td>\n",
       "      <td>0.876518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>Only paid of you use your pto</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.0014362988295033574, -0.022054068744182587...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.876210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>Most likely no unless your state laws require ...</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[-0.004965544678270817, -0.02076898328959942, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.875843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>Protected Paid Time Off (PPTO is earned by eve...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.019739048555493355, -0.010298198089003563,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855539</td>\n",
       "      <td>0.875277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>How the hell do they Calculate PTO? Cause, at ...</td>\n",
       "      <td>WalmartEmployees</td>\n",
       "      <td>[-0.02035108581185341, -0.006431127432733774, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872277</td>\n",
       "      <td>0.875250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>PTO should get paid out‚Ä¶</td>\n",
       "      <td>BestBuyWorkers</td>\n",
       "      <td>[0.002405428094789386, -0.021997543051838875, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.874631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>I commented yesterday but I wanted to add- any...</td>\n",
       "      <td>RiteAid</td>\n",
       "      <td>[0.0019119379576295614, -0.014628302305936813,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.873956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reddit_text  reddit_subreddit  \\\n",
       "5678   Not sure about PTO, but the most ppto you can ...  WalmartEmployees   \n",
       "2620   I get 21 mins of ppto earned per shift (10 hrs...  WalmartEmployees   \n",
       "5655   Not everyone gets ppto at the same rate. You s...  WalmartEmployees   \n",
       "1619   Full timers generally earn pto faster. But mos...  WalmartEmployees   \n",
       "301    All associates earn PPTO, which is intended fo...  WalmartEmployees   \n",
       "1517   It varies greatly by state/location and store ...           RiteAid   \n",
       "10041                             overtime, bonuses, PTO  WalmartEmployees   \n",
       "80     1.00 = one hour.So you have almost an hour of ...  WalmartEmployees   \n",
       "3324   I was just remembering earlier that it‚Äôs suppo...  WalmartEmployees   \n",
       "2276   It is not a month if pto bro when you first ge...    BestBuyWorkers   \n",
       "6693   So they paid you slightly less per hour then t...  WalmartEmployees   \n",
       "4867   Just went through onboarding (for Walmart dist...  WalmartEmployees   \n",
       "1409            In CA they paid out my 400 hours of PTO.           RiteAid   \n",
       "1297   Hours cut to 32 hrs a week again for me too fo...    BestBuyWorkers   \n",
       "6000                       Only paid of you use your pto  WalmartEmployees   \n",
       "2808   Most likely no unless your state laws require ...    BestBuyWorkers   \n",
       "6225   Protected Paid Time Off (PPTO is earned by eve...  WalmartEmployees   \n",
       "2227   How the hell do they Calculate PTO? Cause, at ...  WalmartEmployees   \n",
       "3213                            PTO should get paid out‚Ä¶    BestBuyWorkers   \n",
       "913    I commented yesterday but I wanted to add- any...           RiteAid   \n",
       "\n",
       "                                           textembedding  Cluster ID  \\\n",
       "5678   [-0.017012763768434525, 0.001875273184850812, ...           0   \n",
       "2620   [0.003536654869094491, 0.007027565501630306, -...           0   \n",
       "5655   [-0.008390921168029308, 0.01311011053621769, -...           0   \n",
       "1619   [-0.008347814902663231, 0.010986099019646645, ...           0   \n",
       "301    [-0.022059394046664238, -0.0017816615290939808...           0   \n",
       "1517   [0.0023047644644975662, 0.0036134349647909403,...           1   \n",
       "10041  [-0.0038837369065731764, -0.01123464573174715,...           0   \n",
       "80     [0.010056194849312305, 0.01743551343679428, -0...           0   \n",
       "3324   [-0.00040522910421714187, 0.007721611764281988...           0   \n",
       "2276   [0.0026660107541829348, -0.008649304509162903,...           3   \n",
       "6693   [-0.0011713088024407625, -0.010902976617217064...           0   \n",
       "4867   [-0.0019015533616766334, -0.009029080159962177...           0   \n",
       "1409   [0.0038649067282676697, -0.01133443508297205, ...           1   \n",
       "1297   [-0.005697236862033606, 0.002120997989550233, ...           3   \n",
       "6000   [-0.0014362988295033574, -0.022054068744182587...           0   \n",
       "2808   [-0.004965544678270817, -0.02076898328959942, ...           3   \n",
       "6225   [-0.019739048555493355, -0.010298198089003563,...           0   \n",
       "2227   [-0.02035108581185341, -0.006431127432733774, ...           0   \n",
       "3213   [0.002405428094789386, -0.021997543051838875, ...           3   \n",
       "913    [0.0019119379576295614, -0.014628302305936813,...           1   \n",
       "\n",
       "       cos_angles  avg_cos_angles  \n",
       "5678     0.881989        0.909629  \n",
       "2620     0.877869        0.904211  \n",
       "5655     0.874638        0.899730  \n",
       "1619     0.879252        0.899054  \n",
       "301      0.879523        0.891735  \n",
       "1517     0.866713        0.888629  \n",
       "10041    0.873787        0.888385  \n",
       "80       0.863413        0.885810  \n",
       "3324     0.857598        0.885746  \n",
       "2276     0.864908        0.884134  \n",
       "6693     0.852667        0.882879  \n",
       "4867     0.878480        0.882403  \n",
       "1409     0.851739        0.880104  \n",
       "1297     0.855249        0.876518  \n",
       "6000     0.861380        0.876210  \n",
       "2808     0.853800        0.875843  \n",
       "6225     0.855539        0.875277  \n",
       "2227     0.872277        0.875250  \n",
       "3213     0.858364        0.874631  \n",
       "913      0.847845        0.873956  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmatch_by_avg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feeding the ranked and re-ranked sentences to LLM\n",
    "\n",
    "We introduce a function to generate a prompt for our LLM from top $k$ comments from ranked (or re-ranked comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(df_col, k):\n",
    "    information_to_feed = \"\"\n",
    "    for n, text in zip(range(k), df_col):\n",
    "        information_to_feed += f\"{n+1}: \" + text + \"\\n\"\n",
    "    # concatenate the first top k comments\n",
    "    combined_information = f\"\\nQuery: {query}\\n\\nAnswer the above query by only using the following:\\n\\n{information_to_feed}\\n\\nLLM Response:\"\n",
    "    \n",
    "    return combined_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ranked = rag_prompt(df_bestmatch_cluster['reddit_text'], 5) # prompt generated from top 5 commenets ranked by cos sim to the original query\n",
    "prompt_reranked = rag_prompt(df_bestmatch_by_avg['reddit_text'], 5) # prompt generated from top 5 commenets reranked by cos sim to the original query + alternative queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**. To reproduce the following, one may need HuggingFace API Key (which is free for the purpose of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:19<00:00,  9.99s/it]\n"
     ]
    }
   ],
   "source": [
    "auto_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "# CPU Enabled uncomment below\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\")\n",
    "# GPU Enabled use below\n",
    "auto_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function that produces a response from our LLM given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    input_ids = auto_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    response = auto_model.generate(**input_ids, max_new_tokens=512)\n",
    "    return auto_tokenizer.decode(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following takes a while, but we believe that this can be improved by using a higher-performing LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_answer1 = llm(prompt_ranked)\n",
    "llm_answer2 = llm(prompt_reranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top 5 commenets ranked by cos sim to the original query \n",
      "\n",
      " <bos>\n",
      "Query: How many PTOs does a regular employee have a year?\n",
      "\n",
      "Answer the above query by only using the following:\n",
      "\n",
      "1: Not sure about PTO, but the most ppto you can earn in a year is 48 hours, with the exception of a couple of states which are unlimited by state law.\n",
      "2: All associates earn PPTO, which is intended for emergencies (car won't start, you're sick, etcFull-time associates also earn PTO, which is intended for scheduled absences (doctor appointments, getting your drivers license renewed, vacations, etc. **Part-time associates do not earn PTO until they have been with the company for 3 years,** because part-time associates should be able to schedule their appointments and other errands on their days off.\n",
      "3: Full timers generally earn pto faster. But most part timers actually earn ppto faster. For most associates in most states, ppto is 1 hour for every 30 hours worked. In most states the ppto accrual rate doesn‚Äôt change over time (aside from with part timers, who get an increase at their 3rd year\n",
      "4: Just went through onboarding (for Walmart distribution and my chart clearly has 1 PPTO/30 hrs worked regardless of tenure. Regular pto is closer to how you described. YMMV\n",
      "5: I get 21 mins of ppto earned per shift (10 hrs and 19 mins of pto ... some states have different rules/laws but so I earn 84 minutes of ppto a week and 76 mins of regular\n",
      "\n",
      "\n",
      "LLM Response: Regular employees typically earn 48 hours of paid time off per year, with the exception of a few states that have unlimited PTO by state law.<eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"Using top 5 commenets ranked by cos sim to the original query \\n\\n\", llm_answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top 5 commenets reranked by cos sim to the original query + alternative queries \n",
      "\n",
      " <bos>\n",
      "Query: How many PTOs does a regular employee have a year?\n",
      "\n",
      "Answer the above query by only using the following:\n",
      "\n",
      "1: Not sure about PTO, but the most ppto you can earn in a year is 48 hours, with the exception of a couple of states which are unlimited by state law.\n",
      "2: I get 21 mins of ppto earned per shift (10 hrs and 19 mins of pto ... some states have different rules/laws but so I earn 84 minutes of ppto a week and 76 mins of regular\n",
      "3: Not everyone gets ppto at the same rate. You start earning from day one and it‚Äôs available to use after 90 days. If you‚Äôre part time and less than 3 years, it‚Äôs 1 ppto hour for every 43.33 hours worked. Full timers, and part timers after 3 years, get 1 ppto hour for every 30 hours worked. Some states have no max. And if you work more than 2080 hours in a year then you will max out on pto\n",
      "4: Full timers generally earn pto faster. But most part timers actually earn ppto faster. For most associates in most states, ppto is 1 hour for every 30 hours worked. In most states the ppto accrual rate doesn‚Äôt change over time (aside from with part timers, who get an increase at their 3rd year\n",
      "5: All associates earn PPTO, which is intended for emergencies (car won't start, you're sick, etcFull-time associates also earn PTO, which is intended for scheduled absences (doctor appointments, getting your drivers license renewed, vacations, etc. **Part-time associates do not earn PTO until they have been with the company for 3 years,** because part-time associates should be able to schedule their appointments and other errands on their days off.\n",
      "\n",
      "\n",
      "LLM Response: According to the passage, regular employees have a maximum of 48 hours of PTO per year.<eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"Using top 5 commenets reranked by cos sim to the original query + alternative queries \\n\\n\", llm_answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of retrieval\n",
    "\n",
    "Note that it is rather difficult to say which LLM responses are better. Moreover, we note that our goal is NOT to get the answer that is absolutely correct but a relevant one among the reddit comments that we put in. For example, the answer may change over time, unless we update the input comments.\n",
    "\n",
    "Hence, we use use both of the LLM responses as ground truths and compare the top 50 retrievals from the two methods:\n",
    "* Method 1: Naive RAG using cosine similairties against the original query\n",
    "* Method 2: Not-so-naive RAG using average cosine similairties against multiple similar queries, including the original one\n",
    "\n",
    "The following function separates the LLM response from an LLM answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular employees typically earn 48 hours of paid time off per year, with the exception of a few states that have unlimited PTO by state law.\n",
      "According to the passage, regular employees have a maximum of 48 hours of PTO per year.\n"
     ]
    }
   ],
   "source": [
    "def llm_answer_to_response(answer):\n",
    "    start = answer.find(\"LLM Response:\")\n",
    "    end = answer.find(\"<eos>\")\n",
    "    return answer[start+len(\"LLM Response:\")+1:end]\n",
    "\n",
    "print(llm_answer_to_response(llm_answer1))\n",
    "print(llm_answer_to_response(llm_answer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_1 = llm_answer_to_response(llm_answer1)\n",
    "truth_2 = llm_answer_to_response(llm_answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_1 = []\n",
    "vectors_2 = []\n",
    "\n",
    "for i in range(50):\n",
    "    vectors_1.append(df_bestmatch_cluster.get('textembedding').iloc[i])\n",
    "    vectors_2.append(df_bestmatch_by_avg.get('textembedding').iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric 1: cosine precision\n",
    "The following is a function with which we evaluate the retrieval from each method. Let $\\boldsymbol{t}_1$ and $\\boldsymbol{t}_2$ be the truth vectors. For each vector $\\boldsymbol{v}$ from a batch, the cosine similarities $\\cos(\\boldsymbol{t}_1, \\boldsymbol{v})$ and $\\cos(\\boldsymbol{t}_2, \\boldsymbol{v})$ are in the interval $[-1, 1]$, but in all of our examples, we know they are in $[0, 1]$. We simply take the average of the two to measure how truthful $\\boldsymbol{v}$ is. Note that the closer the average is to $1$, the more truthful $\\boldsymbol{v}$ is.\n",
    "\n",
    "Recall the definition of **precision**:\n",
    "$$\\mathrm{Precision} := \\frac{\\mathrm{Relevant \\ retrieved \\ instances}}{\\mathrm{All \\ retrieved \\ instances}}.$$\n",
    "\n",
    "Given a batch $B$, we define the **cosine precision** as follows:\n",
    "\n",
    "$$\\mathrm{Cosine \\ Precision \\ of } \\ B := \\frac{1}{2|B|}\\sum_{\\boldsymbol{v} \\in B}  (\\cos(\\boldsymbol{t}_1, \\boldsymbol{v}) + \\cos(\\boldsymbol{t}_2, \\boldsymbol{v}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_precision(batch, t_1, t_2):\n",
    "    t_1 = np.array(t_1)\n",
    "    t_2 = np.array(t_2)\n",
    "    \n",
    "    sum = 0\n",
    "\n",
    "    for v in batch:\n",
    "        v = np.array(v)\n",
    "        sum += (cos_angle(t_1, v) + cos_angle(t_2, v))\n",
    "    return sum / (2*len(batch))\n",
    "\n",
    "t_1 = get_sentence_embedding(truth_1)\n",
    "t_2 = get_sentence_embedding(truth_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86954928]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_precision(vectors_1, t_1, t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8786808]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_precision(vectors_2, t_1, t_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric 2: ranked cosine precision\n",
    "\n",
    "The following is a function that evaluates not only the retrieval, but also evaluates the ranking for the retrieved contexts.\n",
    "\n",
    "Assume we retrieved $K$ comments in the context, ranked as $B = (x_1, \\ldots, x_K)$.\n",
    "\n",
    "We call the **precision at rank $m$** the cosine precision for the truncated context $B_m := (x_1, \\ldots, x_m)$. And the ranked cosine precision is the average of these precisions.\n",
    "\n",
    "$$\n",
    "\\text{Ranked Cosine Precision of } B := \\frac{1}{K} \\sum_{m = 1}^{K} \\text{Cosine Precision of } B_m.\n",
    "$$\n",
    "\n",
    "Under this measurement, those comments ranked higher in the retrieved context will have a higher impact to the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_rank_precision(batch, t_1, t_2):\n",
    "    sum = 0\n",
    "\n",
    "    for m in range(1, len(batch)+1):\n",
    "        sum += cos_precision(batch[:m], t_1, t_2)\n",
    "\n",
    "    return sum / len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87982534]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_rank_precision(vectors_1, t_1, t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88779141]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_rank_precision(vectors_2, t_1, t_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "As we have seen in the example above, our averaging method improves the overall retrieval better by getting rid of possibly unrelated retrieved data by comparisions with multiple similar queries to the original one. The LLM API took some time, but it is evident that any stronger LLM we use would only make this process faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
